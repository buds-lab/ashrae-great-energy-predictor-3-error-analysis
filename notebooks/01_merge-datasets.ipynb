{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598965338368",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets\n",
    "In this notebook the following task will be done:\n",
    "- Create `pickle.gz` files of `test` and `solution` datasets\n",
    "- Merge submissions datasets with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gzip\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\\\\source\\\\\")\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = \"..\\\\data\\\\original\\\\\"\n",
    "path_out = \"..\\\\data\\\\processed\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress solution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.read_csv(path_in + \"solution\\solution.csv\", usecols=[\"row_id\",\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative values with NaN\n",
    "solution = solution.replace(-9999.000, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 41697600 entries, 0 to 41697599\nData columns (total 2 columns):\n #   Column         Dtype  \n---  ------         -----  \n 0   row_id         int64  \n 1   meter_reading  float64\ndtypes: float64(1), int64(1)\nmemory usage: 636.3 MB\n"
    }
   ],
   "source": [
    "solution.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "row_id           0.000000\nmeter_reading    2.026966\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "solution.isna().sum()*100 / len(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = gzip.GzipFile(path_in + f'solution\\\\solution.pickle.gz', 'wb', 9)\n",
    "file.write(pickle.dumps(solution))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_in + \"test\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = gzip.GzipFile(path_out + f'test.pickle.gz', 'wb', 9)\n",
    "file.write(pickle.dumps(df))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add solution to top50 submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load solution\n",
    "solution = pd.read_pickle(path_in + \"solution\\\\solution.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "50"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#Top50 files\n",
    "top50_files = glob.glob(path_in + \"top50_submissions\\\\*\")\n",
    "len(top50_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'top50_files' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-cd2b46b8712e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m51\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop50_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# file id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top50_files' is not defined"
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "end = 51\n",
    "\n",
    "for datafile in top50_files[start:end]:\n",
    "\n",
    "    # file id\n",
    "    name = datafile.split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "\n",
    "    # Print progress\n",
    "    number = top50_files.index(datafile) + 1\n",
    "    total = len(top50_files)\n",
    "    progress = round(number * 100 / total,2)\n",
    "    print(f\"{name} - {progress}% ({number} of {len(top50_files)})\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_pickle(datafile).rename(columns={\"meter_reading\":\"submission\"})\n",
    "    print(f\"Data loaded\")\n",
    "\n",
    "    # Merge\n",
    "    df = pd.merge(df, solution, how=\"inner\", on=\"row_id\")\n",
    "    print(f\"Data merged\")\n",
    "\n",
    "    # Export df\n",
    "    file = gzip.GzipFile(path_out + f'merged\\\\submissions_solution\\\\sub{name}_solution.pickle.gz', 'wb', 6)\n",
    "    file.write(pickle.dumps(df))\n",
    "    file.close()\n",
    "    print(f\"Data exported\")\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "50"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Sub + solution files\n",
    "files = glob.glob(path_out + 'merged\\\\submissions_solution\\\\*\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n"
    }
   ],
   "source": [
    "# Test data\n",
    "test = pd.read_pickle(path_in + \"test\\\\test.pickle.gz\")\n",
    "test = utils.reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 41697600 entries, 0 to 41697599\nData columns (total 4 columns):\n #   Column       Dtype \n---  ------       ----- \n 0   row_id       int32 \n 1   building_id  int16 \n 2   meter        int8  \n 3   timestamp    object\ndtypes: int16(1), int32(1), int8(1), object(1)\nmemory usage: 596.5+ MB\n"
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sub13577404 - 2.0% (1 of 50)\nMem. usage decreased to 795.32 Mb (37.5% reduction)\nData loaded\nData merged\nData exported\n\n"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 1\n",
    "\n",
    "for datafile in files[start:end]:\n",
    "\n",
    "    # file id\n",
    "    name = datafile.split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "\n",
    "    # Print progress\n",
    "    number = files.index(datafile) + 1\n",
    "    total = len(files)\n",
    "    progress = round(number * 100 / total,2)\n",
    "    print(f\"{name} - {progress}% ({number} of {len(files)})\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_pickle(datafile)\n",
    "    df = utils.reduce_mem_usage(df)\n",
    "    print(f\"Data loaded\")\n",
    "\n",
    "    # Merge\n",
    "    df = pd.merge(df, test, how=\"inner\", on=\"row_id\").drop(\"row_id\",axis=1)\n",
    "    print(f\"Data merged\")\n",
    "\n",
    "    # Export df\n",
    "    file = gzip.GzipFile(path_out + f'merged\\\\{name}_merged.pickle.gz', 'wb', 6)\n",
    "    file.write(pickle.dumps(df))\n",
    "    file.close()\n",
    "    print(f\"Data exported\")\n",
    "    \n",
    "    print(\"\")"
   ]
  }
 ]
}