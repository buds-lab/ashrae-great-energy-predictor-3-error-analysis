{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find patterns by building\n",
    "In this notebook the following tasks will be accomplished:\n",
    "\n",
    "1. Create arrays for heatmap, one per meter-site.\n",
    "2. Find errors in those arrays.\n",
    "    - Good fit: `rmsle_scaled` < 0.1\n",
    "    - In range errors (A): 0.1 <= `rmsle_scaled` <= 0.3\n",
    "      - single buiding in range long term (A1): time_consequitve_error > 3 days\n",
    "      - single building in range mid term (A2): 1 day < time_consequitve_error <= 3 days\n",
    "      - single building in range short term (A3): time_consequitve_error = 1\n",
    "      - single building in range fluctuatiom (A4):\n",
    "    - Out of range errors (B): `rmsle_scaled` > 0.3\n",
    "      - single buiding out of range long term (B1): time_consequitve_error > 3 days\n",
    "      - single building out of range mid term (B2): 1 day < time_consequitve_error <= 3 days\n",
    "      - single building out of range short term (B3): time_consequitve_error = 1\n",
    "      - single building out of range fluctuatiom (B4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\\\\source\\\\\")\n",
    "import utils as utils\n",
    "import glob\n",
    "\n",
    "# Data and numbers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import ticker\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"..\\\\data\\\\processed\\\\summary\\\\\"\n",
    "path_leak = \"..\\\\data\\\\leaked\\\\\"\n",
    "path_meta = \"..\\\\data\\\\original\\\\metadata\\\\\"\n",
    "path_arrays = \"..\\\\data\\\\processed\\\\arrays\\\\\"\n",
    "path_res = \"..\\\\results\\\\by_bdg\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmaps_comp(df,df_bool):\n",
    "\n",
    "    \"\"\"This function plots two heatmaps side by side:\n",
    "        - The original heatmap\\n\n",
    "        - A heatmap where only values over ´tresh_error´ are colored\\n\n",
    "\n",
    "        df: original values for a meter-site.\n",
    "        df_bool: masked df for that meter-site, where only values over `tresh_error` are 1 (otherwise, 0)\\n\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, sharex = True, sharey=True, figsize=(16,8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Get the data\n",
    "    y = np.linspace(0, len(df), len(df)+1)\n",
    "    x = pd.date_range(start='2017-01-01', end='2018-12-31')\n",
    "    cmap = plt.get_cmap('YlOrRd')\n",
    "\n",
    "    for i,data in enumerate([df_bool,df]):\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[i]\n",
    "        data = data\n",
    "        qmesh = ax.pcolormesh(x, y, data, cmap=cmap, rasterized=True, vmin=0, vmax=1)\n",
    "\n",
    "        # Axis\n",
    "        plt.locator_params(axis='y', nbins=len(list(data.index)) + 1)\n",
    "        ax.axis('tight') \n",
    "        ax.xaxis_date() # Set up as dates\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%y')) # set date's format\n",
    "        ax.set_yticklabels(list(df_bool.index)) # omit building ID on y axis\n",
    "\n",
    "    # Color bar  \n",
    "    cbar = fig.colorbar(qmesh, ax=ax)\n",
    "    cbar.set_label('Min-Max scaled RMSLE')\n",
    "\n",
    "    fig.suptitle(f\"{meter} - site {site}\", y = 1.015, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.12)\n",
    "    #plt.pcolormesh(df, cmap='YlOrRd', rasterized=True)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoodFit(file_path, t_error, name, plot=False):\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(file).set_index(\"building_id\")\n",
    "    # Color only error greater than treshold\n",
    "    df_bool = (df > t_error).astype(int)\n",
    "\n",
    "    if plot==True:\n",
    "        fig = heatmaps_comp(df,df_bool)\n",
    "\n",
    "    df_bool = df_bool.replace([0,1],[1,np.nan])\n",
    "\n",
    "    return df_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_1(file, t_error_good, t_error, t_days, name, plot=False):\n",
    "    \"\"\"\n",
    "    Calculates errors type 1 in file: consecutive errors longer than `t_days`.\n",
    "\n",
    "    file: (string) path to meter-site normalizes RMSLE array (building_id vs. date).\\n\n",
    "    t_error_good: (float) threshold for RMSLE value; values below this are considered a good fit.\\n\n",
    "    t_error: (float) threshold for RMSLE value.\\n\n",
    "    t_day: (int) number of minimum consecutive days to consider it a type 1 error.\\n\n",
    "    name: (string) \"A\" or \"B\". If \"A\", in range values are selected. If \"B\", out of range values.\\n\n",
    "    plot: (bool) wheter to plot or not.\\n\n",
    "\n",
    "    returns:\n",
    "    A sparse dataframe, with 1 in those buildings-dates an error ocurs.\\n\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    df = pd.read_csv(file,index_col=\"building_id\")\n",
    "    # Keep only selected region\n",
    "    if \"A\" in name:\n",
    "        df_bool = ((df >= t_error_good) & (df <= t_error)).astype(int)\n",
    "    elif \"B\" in name:\n",
    "        df_bool = (df > t_error).astype(int).astype(int)\n",
    "    else:\n",
    "        print(\"Error not recognized.\")\n",
    "        return None\n",
    "\n",
    "    # Create empty df to assign errors\n",
    "    df_empty = df[df<0]\n",
    "\n",
    "    ### GET HIGH ERRORS BY BDG ###\n",
    "    dfs = []\n",
    "    df_bdg = df_bool.T\n",
    "\n",
    "    for col in df_bdg.columns:\n",
    "        # Select one building\n",
    "        df1 = df_bdg[[col]]\n",
    "        # Tag groups of consequtive equal numbers\n",
    "        df1['grp'] = (df1[col] != df1[col].shift()).cumsum()\n",
    "        # Filter values == 1 (error higher than t_error)\n",
    "        df1 = df1.loc[df1[col] == 1,].reset_index().rename(columns={\"index\":\"date\"}, index={\"building_id\":\"index\"})[[\"date\",\"grp\"]]\n",
    "        # Add bdg number\n",
    "        df1[\"building_id\"] = col\n",
    "        # Get buildings with high error during period longer than t_days\n",
    "        by_group = df1[[\"date\",\"grp\"]].groupby(\"grp\").count().reset_index() # group\n",
    "        groups = list(by_group.loc[by_group.date > t_days, \"grp\"]) # get list of groups\n",
    "        mt = df1[df1.grp.isin(groups) == True] # filter and get only those groups\n",
    "        mt[\"error\"] = 1\n",
    "        # Append to list\n",
    "        dfs.append(mt)\n",
    "\n",
    "    # Concat all\n",
    "    df2 = pd.concat(dfs)\n",
    "    # Pivot\n",
    "    df2 = df2.pivot(index=\"date\",columns=\"building_id\", values=\"error\").T\n",
    "\n",
    "    # Replace on df_empty\n",
    "    df_empty.update(df2)\n",
    "\n",
    "    if plot == True:\n",
    "        fig = heatmaps_comp(df,df_empty.replace(np.nan,0))\n",
    "\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_2(file, t_error_good, t_error, t_days, name, plot=False):\n",
    "    \"\"\"\n",
    "    Calculates errors type 2 in file: consecutive errors longer than 1 day and shorter or equal than `t_days`.\n",
    "\n",
    "    file: (string) path to meter-site normalizes RMSLE array (building_id vs. date).\\n\n",
    "    t_error_good: (float) threshold for RMSLE value; values below this are considered a good fit.\\n\n",
    "    t_error: (float) threshold for RMSLE value.\\n\n",
    "    t_day: (int) number of minimum consecutive days to consider it a type 1 error.\\n\n",
    "    name: (string) \"A\" or \"B\". If \"A\", in range values are selected. If \"B\", out of range values.\\n\n",
    "    plot: (bool) wheter to plot or not.\\n\n",
    "\n",
    "    returns:\n",
    "    A sparse dataframe, with 1 in those buildings-dates an error ocurs.\\n\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    df = pd.read_csv(file,index_col=\"building_id\")\n",
    "    # Keep only selected region\n",
    "    if \"A\" in name:\n",
    "        df_bool = ((df >= t_error_good) & (df <= t_error)).astype(int)\n",
    "    elif \"B\" in name:\n",
    "        df_bool = (df > t_error).astype(int).astype(int)\n",
    "    else:\n",
    "        print(\"Error not recognized.\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # Create empty df to assign errors\n",
    "    df_empty = df[df<0]\n",
    "\n",
    "    ### GET HIGH ERRORS BY BDG ###\n",
    "    dfs = []\n",
    "    df_bdg = df_bool.T\n",
    "\n",
    "    for col in df_bdg.columns:\n",
    "        # Select one building\n",
    "        df1 = df_bdg[[col]]\n",
    "        # Tag groups of consequtive equal numbers\n",
    "        df1['grp'] = (df1[col] != df1[col].shift()).cumsum()\n",
    "        # Filter values == 1 (error higher than t_error)\n",
    "        df1 = df1.loc[df1[col] == 1,].reset_index().rename(columns={\"index\":\"date\"}, index={\"building_id\":\"index\"})[[\"date\",\"grp\"]]\n",
    "        # Add bdg number\n",
    "        df1[\"building_id\"] = col\n",
    "        # Get buildings with high error during period longer than t_dates\n",
    "        by_group = df1[[\"date\",\"grp\"]].groupby(\"grp\").count().reset_index() # group\n",
    "        groups = list(by_group.loc[(by_group.date > 1) & (by_group.date <= t_days), \"grp\"]) # get list of groups\n",
    "        mt = df1[df1.grp.isin(groups) == True] # filter and get only those groups\n",
    "        mt[\"error\"] = 1\n",
    "        # Append to list\n",
    "        dfs.append(mt)\n",
    "\n",
    "    # Concat all\n",
    "    df2 = pd.concat(dfs)\n",
    "    # Pivot\n",
    "    df2 = df2.pivot(index=\"date\",columns=\"building_id\", values=\"error\").T\n",
    "\n",
    "    # Replace on df_empty\n",
    "    df_empty.update(df2)\n",
    "\n",
    "    if plot == True:\n",
    "        fig = heatmaps_comp(df,df_empty.replace(np.nan,0))\n",
    "\n",
    "\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_3(file, t_error_good, t_error, name, plot=False):\n",
    "    \"\"\"\n",
    "    Calculates errors type 2 in file: errors during 1 day.\n",
    "\n",
    "    file: (string) path to meter-site normalizes RMSLE array (building_id vs. date).\\n\n",
    "    t_error_good: (float) threshold for RMSLE value; values below this are considered a good fit.\\n\n",
    "    t_error: (float) threshold for RMSLE value.\\n\n",
    "    t_day: (int) number of minimum consecutive days to consider it a type 1 error.\\n\n",
    "    name: (string) \"A\" or \"B\". If \"A\", in range values are selected. If \"B\", out of range values.\\n\n",
    "    plot: (bool) wheter to plot or not.\\n\n",
    "\n",
    "    returns:\n",
    "    A sparse dataframe, with 1 in those buildings-dates an error ocurs.\\n\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    df = pd.read_csv(file,index_col=\"building_id\")\n",
    "    # Keep only selected region\n",
    "    if \"A\" in name:\n",
    "        df_bool = ((df >= t_error_good) & (df <= t_error)).astype(int)\n",
    "    else:\n",
    "        df_bool = (df > t_error).astype(int).astype(int)\n",
    "\n",
    "    # Create empty df to assign errors\n",
    "    df_empty = df[df<0]\n",
    "\n",
    "    ### GET HIGH ERRORS BY BDG ###\n",
    "    dfs = []\n",
    "    df_bdg = df_bool.T\n",
    "\n",
    "    for col in df_bdg.columns:\n",
    "        # Select one building\n",
    "        df1 = df_bdg[[col]]\n",
    "        # Tag groups of consequtive equal numbers\n",
    "        df1['grp'] = (df1[col] != df1[col].shift()).cumsum()\n",
    "        # Filter values == 1 (error higher than t_error)\n",
    "        df1 = df1.loc[df1[col] == 1,].reset_index().rename(columns={\"index\":\"date\"}, index={\"building_id\":\"index\"})[[\"date\",\"grp\"]]\n",
    "        # Add bdg number\n",
    "        df1[\"building_id\"] = col\n",
    "        # Get buildings with high error during period longer than t_dates\n",
    "        by_group = df1[[\"date\",\"grp\"]].groupby(\"grp\").count().reset_index() # group\n",
    "        groups = list(by_group.loc[by_group.date == 1, \"grp\"]) # get list of groups\n",
    "        mt = df1[df1.grp.isin(groups) == True] # filter and get only those groups\n",
    "        mt[\"error\"] = 1\n",
    "        # Append to list\n",
    "        dfs.append(mt)\n",
    "\n",
    "    # Concat all\n",
    "    df2 = pd.concat(dfs)\n",
    "    # Pivot\n",
    "    df2 = df2.pivot(index=\"date\",columns=\"building_id\", values=\"error\").T\n",
    "\n",
    "    # Replace on df_empty\n",
    "    df_empty.update(df2)\n",
    "\n",
    "    if plot == True:\n",
    "        fig = heatmaps_comp(df,df_empty.replace(np.nan,0))\n",
    "\n",
    "\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_4(file, t_error_good, t_error, w, t_w, plot=False):\n",
    "    \"\"\"\n",
    "    Calculates errors type 4 in file: fluctuating errors, shorter than `t_days`.\\n\n",
    "\n",
    "    file: path to meter-site short term error (building_id vs. date).\\n\n",
    "    t_error_good: (float) threshold for RMSLE value; values below this are considered a good fit.\\n\n",
    "    t_error: (float) threshold for RMSLE value.\\n\n",
    "    w: time window to check error.\\n\n",
    "    t_w: proportion of error during time window.\\n\n",
    "    name: (string) \"A\" or \"B\". If \"A\", in range values are selected. If \"B\", out of range values.\\n\n",
    "    plot: (bool) wheter to plot or not.\\n\n",
    "\n",
    "    returns:\n",
    "    A sparse dataframe, with 1 in those buildings-dates an error ocurs.\\n\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    df = pd.read_csv(file,index_col=\"building_id\")\n",
    "    # Color only error greater than treshold\n",
    "    df_bool = df.replace(np.nan,0)\n",
    "    \n",
    "    \"\"\"# Keep only selected region\n",
    "    if \"A\" in name:\n",
    "        df_bool = ((df >= t_error_good) & (df <= t_error)).astype(int)\n",
    "    elif \"B\" in name:\n",
    "        df_bool = (df > t_error).astype(int).astype(int)\n",
    "    else:\n",
    "        print(\"Error not recognized.\")\n",
    "        return None\"\"\"\n",
    "    \n",
    "    ### GET HIGH ERRORS BY BDG ###\n",
    "    dfs = []\n",
    "    df_bdg = df_bool.T\n",
    "\n",
    "    ### CHECK IF t_w PROPORTION IS EXCEED DURIN w TIME PERIOD ###\n",
    "    for col in df_bdg.columns:\n",
    "        # Select one building\n",
    "        df1 = df_bdg[[col]].reset_index().rename(columns={\"index\":'date'}).fillna(0)\n",
    "        # Calculate rolling sum\n",
    "        df1[\"rol_sum\"] = df1[col].rolling(w).sum()\n",
    "        # Get index of last row of windows, which sum is over threshold\n",
    "        idx = df1[df1[\"rol_sum\"] > w*t_w].index\n",
    "        # Mark whole window\n",
    "        if len(idx) > 0:\n",
    "            for ix in list(idx):\n",
    "                i0 = ix-w\n",
    "                it = ix\n",
    "                df1.loc[i0:it,\"mark\"] = df1.loc[i0:it,col] #copy original values in window\n",
    "        else:\n",
    "            df1[\"mark\"] = np.nan\n",
    "        # Rename and complete df\n",
    "        df1 = df1.set_index(\"date\").drop([col,\"rol_sum\"],axis=1).rename(columns={\"mark\":col})\n",
    "        # Append\n",
    "        dfs.append(df1)\n",
    "\n",
    "    #Create errors df\n",
    "    df_error = pd.concat(dfs,axis=1).replace(0,np.nan).T\n",
    "\n",
    "    if plot == True:\n",
    "        fig = heatmaps_comp(df,df_error.replace(np.nan,0))\n",
    "\n",
    "    return df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter: electricity\n",
      "Min rmsle: 0.03999936208128929. Max rmsle: 8.138672828674316\n",
      "Min rmsle_scaled: 0.0. Max rmsle_scaled: 1.0\n",
      "\n",
      "Meter: chilledwater\n",
      "Min rmsle: 0.07809336483478546. Max rmsle: 8.397016525268555\n",
      "Min rmsle_scaled: 0.0. Max rmsle_scaled: 0.9999999999999999\n",
      "\n",
      "Meter: hotwater\n",
      "Min rmsle: 0.11213328689336777. Max rmsle: 8.06053352355957\n",
      "Min rmsle_scaled: 0.0. Max rmsle_scaled: 1.0\n",
      "\n",
      "Meter: steam\n",
      "Min rmsle: 0.0737953633069992. Max rmsle: 9.318635940551758\n",
      "Min rmsle_scaled: 0.0. Max rmsle_scaled: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"meters = [\"electricity\",\"chilledwater\",\"hotwater\",\"steam\"]\n",
    "group = \"site_id\"\n",
    "metric = \"RMSLE\"\n",
    "\n",
    "for meter in meters:\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_pickle(path_data + f\"{meter}_RMSLE.pickle.gz\")\n",
    "\n",
    "    # Remove leaked buidings\n",
    "    leak = pd.read_csv(path_leak + f\"leak_{meter}.csv\")\n",
    "    df = df[df.building_id.isin(leak.building_id) == False]\n",
    "\n",
    "    # Datetime object\n",
    "    df.timestamp = pd.to_datetime(df.timestamp, format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Complete missing dates\n",
    "    df = utils.complete_data(df,\"2017-01-01\",\"2018-12-31\")\n",
    "\n",
    "    # Merge with metadata\n",
    "    meta_bdg = pd.read_csv(path_meta + \"building_metadata.csv\")\n",
    "    df = pd.merge(df, meta_bdg, how=\"left\", on=\"building_id\")\n",
    "\n",
    "    # Scale metric between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_rmsle = scaler.fit_transform(np.array(df.rmsle).reshape(-1, 1))\n",
    "    # Add to df\n",
    "    df[\"rmsle_scaled\"] = scaled_rmsle\n",
    "    # Print limits\n",
    "    print(f\"Meter: {meter}\")\n",
    "    print(f\"Min rmsle: {df.rmsle.min()}. Max rmsle: {df.rmsle.max()}\")\n",
    "    print(f\"Min rmsle_scaled: {df.rmsle_scaled.min()}. Max rmsle_scaled: {df.rmsle_scaled.max()}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Create arrays\n",
    "    group_name = list(df[group].unique())\n",
    "\n",
    "    for i,j in enumerate(group_name):\n",
    "\n",
    "        # Filter data\n",
    "        df_grouped = df[df[group] == j]\n",
    "\n",
    "        # Pivot data\n",
    "        pivot_df = df_grouped.pivot(columns=\"timestamp\", index=\"building_id\", values=\"rmsle_scaled\")\n",
    "\n",
    "        # Sort in descending order (sum RMSLE)\n",
    "        pivot_df[\"sum\"] = np.sum(pivot_df,axis=1).tolist()\n",
    "        pivot_df = pivot_df.sort_values(\"sum\")\n",
    "        pivot_df.drop(\"sum\",axis=1, inplace=True)\n",
    "\n",
    "        # Save df\n",
    "        pivot_df.to_csv(path_arrays + f\"{meter}_{metric}_site_{j}.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meters = [\"chilledwater\",\"electricity\",\"hotwater\",\"steam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good fit (Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - Site 10\n",
      "chilledwater - Site 11\n",
      "chilledwater - Site 13\n",
      "chilledwater - Site 14\n",
      "chilledwater - Site 6\n",
      "chilledwater - Site 7\n",
      "chilledwater - Site 9\n",
      "\n",
      "electricity - Site 10\n",
      "electricity - Site 11\n",
      "electricity - Site 12\n",
      "electricity - Site 13\n",
      "electricity - Site 14\n",
      "electricity - Site 3\n",
      "electricity - Site 4\n",
      "electricity - Site 5\n",
      "electricity - Site 6\n",
      "electricity - Site 7\n",
      "electricity - Site 8\n",
      "electricity - Site 9\n",
      "\n",
      "hotwater - Site 1\n",
      "hotwater - Site 10\n",
      "hotwater - Site 11\n",
      "hotwater - Site 14\n",
      "hotwater - Site 7\n",
      "\n",
      "steam - Site 13\n",
      "steam - Site 14\n",
      "steam - Site 6\n",
      "steam - Site 7\n",
      "steam - Site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - Site {site}\")\n",
    "        #Create df\n",
    "        df = GoodFit(file, 0.1, \"Z\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_Z_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In range errors (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_1(file,0.1, 0.3, 3,\"A1\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_A1_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_2(file,0.1, 0.3, 3, \"A2\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_A2_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_3(file,0.1, 0.3,\"A3\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_A3_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4\n",
    "This error is based on A3 errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_res + f\"{meter}_A3_*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0].split(\"site\")[1]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_4(file,0.1, 0.3, 30, 0.1, plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_A4_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of range errors (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_1(file,0.1, 0.3, 3,\"B1\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_B1_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_2(file,0.1, 0.3, 3, \"B2\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_B2_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_arrays + f\"{meter}*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_3(file,0.1, 0.3,\"B3\", plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_B3_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilledwater - site 10\n",
      "chilledwater - site 11\n",
      "chilledwater - site 13\n",
      "chilledwater - site 14\n",
      "chilledwater - site 6\n",
      "chilledwater - site 7\n",
      "chilledwater - site 9\n",
      "\n",
      "electricity - site 10\n",
      "electricity - site 11\n",
      "electricity - site 12\n",
      "electricity - site 13\n",
      "electricity - site 14\n",
      "electricity - site 3\n",
      "electricity - site 4\n",
      "electricity - site 5\n",
      "electricity - site 6\n",
      "electricity - site 7\n",
      "electricity - site 8\n",
      "electricity - site 9\n",
      "\n",
      "hotwater - site 1\n",
      "hotwater - site 10\n",
      "hotwater - site 11\n",
      "hotwater - site 14\n",
      "hotwater - site 7\n",
      "\n",
      "steam - site 13\n",
      "steam - site 14\n",
      "steam - site 6\n",
      "steam - site 7\n",
      "steam - site 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in meters:\n",
    "    #Get list of files\n",
    "    files = glob.glob(path_res + f\"{meter}_B3_*.csv\")\n",
    "\n",
    "    for file in files:\n",
    "        # Site id\n",
    "        site = file.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0].split(\"site\")[1]\n",
    "        print(f\"{meter} - site {site}\")\n",
    "        # Create df\n",
    "        df = error_4(file,0.1, 0.3, 60, 0.1, plot=False)\n",
    "        # Save df\n",
    "        df.to_csv(f\"{path_res}\\\\{meter}_B4_site{site}.csv\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
